{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Db2 Sample For Scikit-Learn\n",
    "#### Rohith Ravindranath (rohithravin@ibm.com)\n",
    "In this code sample, we will show how to use the Db2 Python driver to import data from our Db2 database. Then, we will use that data to create a machine learning model with scikit-learn.\n",
    "\n",
    "For this example, we will be using the [winequa dataset](https://github.com/zygmuntz/wine-quality/blob/master/winequality/winequality-red.csv), which we have loaded into our Db2 instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data\n",
    "Let's first install and import all the libraries needed for this notebook. Most important we will be installing and importing the db2 python driver `ibm_db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn\n",
    "!easy_install ibm_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# The two python ibm db2 drivers we need\n",
    "import ibm_db\n",
    "import ibm_db_dbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import our data from our data source using the python db2 driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace only <> credentials\n",
    "dsn = \"DRIVER={{IBM DB2 ODBC DRIVER}};\" + \\\n",
    "      \"DATABASE=<DATABASE NAME>;\" + \\\n",
    "      \"HOSTNAME=<HOSTNMAE>;\" + \\\n",
    "      \"PORT=50000;\" + \\\n",
    "      \"PROTOCOL=TCPIP;\" + \\\n",
    "      \"UID=<USERNAME>;\" + \\\n",
    "      \"PWD=<PWD>;\"\n",
    "hdbc  = ibm_db.connect(dsn, \"\", \"\")\n",
    "hdbi = ibm_db_dbi.Connection(hdbc)\n",
    "\n",
    "sql = 'SELECT * FROM <SCHEMA NAME>.<TABLE NAME>'\n",
    "\n",
    "wine = pandas.read_sql(sql,hdbi)\n",
    "#wine = pd.read_csv('data/winequality-red.csv', sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we are going to try and explore our data inorder to gain insight. We hope to be able to make some assumptions of our data before we start modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum price of the data\n",
    "minimum_price = np.amin(wine['quality'])\n",
    "\n",
    "# Maximum price of the data\n",
    "maximum_price = np.amax(wine['quality'])\n",
    "\n",
    "# Mean price of the data\n",
    "mean_price = np.mean(wine['quality'])\n",
    "\n",
    "# Median price of the data\n",
    "median_price = np.median(wine['quality'])\n",
    "\n",
    "# Standard deviation of prices of the data\n",
    "std_price = np.std(wine['quality'])\n",
    "\n",
    "# Show the calculated statistics\n",
    "print(\"Statistics for housing dataset:\\n\")\n",
    "print(\"Minimum price: ${}\".format(minimum_price)) \n",
    "print(\"Maximum price: ${}\".format(maximum_price))\n",
    "print(\"Mean price: ${}\".format(mean_price))\n",
    "print(\"Median price ${}\".format(median_price))\n",
    "print(\"Standard deviation of prices: ${}\".format(std_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = wine.corr()\n",
    "corr_matrix[\"quality\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.hist(bins=50, figsize=(30,25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = wine.boxplot(column=['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned and explored our data. We are ready to build our model that will predict the attribute `quality`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_value = wine['quality']\n",
    "wine_attributes = wine.drop(['quality'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Let us scale our data first \n",
    "sc = StandardScaler()\n",
    "wine_attributes = sc.fit_transform(wine_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to our data\n",
    "pca = PCA(n_components=8)\n",
    "x_pca = pca.fit_transform(wine_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split our data into train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split our data into test and train data\n",
    "x_train, x_test, y_train, y_test = train_test_split( wine_attributes,wine_value, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Logistic Regression to model our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train our model\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Predict using our trained model and our test data\n",
    "lr_predict = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix and accuracy score\n",
    "lr_conf_matrix = confusion_matrix(y_test, lr_predict)\n",
    "lr_acc_score = accuracy_score(y_test, lr_predict)\n",
    "print(lr_conf_matrix)\n",
    "print(lr_acc_score*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
